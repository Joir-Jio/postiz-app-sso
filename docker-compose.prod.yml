# Production Docker Compose for AWS deployment
# This configuration is optimized for container orchestration platforms like ECS/Fargate
# For local testing of production builds only - use managed services in actual AWS deployment

version: '3.8'

x-common-variables: &common-variables
  NODE_ENV: production
  
  # Database Configuration (use AWS RDS in production)
  DATABASE_URL: ${DATABASE_URL:-postgresql://postiz:${DB_PASSWORD}@db:5432/postiz}
  
  # Redis Configuration (use AWS ElastiCache in production)
  REDIS_URL: ${REDIS_URL:-redis://redis:6379}
  
  # JWT and Security
  JWT_SECRET: ${JWT_SECRET}
  ENCRYPTION_KEY: ${ENCRYPTION_KEY}
  
  # API Configuration
  NEXT_PUBLIC_BACKEND_URL: ${NEXT_PUBLIC_BACKEND_URL:-http://backend:3000}
  FRONTEND_URL: ${FRONTEND_URL:-http://frontend:4200}
  
  # External Services
  AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
  AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
  AWS_REGION: ${AWS_REGION:-us-east-1}
  
  # Google Cloud Storage
  GCS_BUCKET_NAME: ${GCS_BUCKET_NAME}
  GOOGLE_APPLICATION_CREDENTIALS: ${GOOGLE_APPLICATION_CREDENTIALS}
  
  # Social Media API Keys
  TWITTER_CLIENT_ID: ${TWITTER_CLIENT_ID}
  TWITTER_CLIENT_SECRET: ${TWITTER_CLIENT_SECRET}
  FACEBOOK_CLIENT_ID: ${FACEBOOK_CLIENT_ID}
  FACEBOOK_CLIENT_SECRET: ${FACEBOOK_CLIENT_SECRET}
  LINKEDIN_CLIENT_ID: ${LINKEDIN_CLIENT_ID}
  LINKEDIN_CLIENT_SECRET: ${LINKEDIN_CLIENT_SECRET}
  YOUTUBE_CLIENT_ID: ${YOUTUBE_CLIENT_ID}
  YOUTUBE_CLIENT_SECRET: ${YOUTUBE_CLIENT_SECRET}
  
  # Monitoring and Logging
  SENTRY_DSN: ${SENTRY_DSN}
  NEW_RELIC_LICENSE_KEY: ${NEW_RELIC_LICENSE_KEY}
  
  # Feature Flags
  ENABLE_SSO: ${ENABLE_SSO:-true}
  NOT_SECURED: ${NOT_SECURED:-false}

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"
    labels: "service"

services:
  # ============================================================================
  # Frontend Service (Next.js)
  # ============================================================================
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
      target: frontend
      args:
        - NEXT_PUBLIC_VERSION=${VERSION:-1.0.0}
    image: postiz/frontend:${VERSION:-latest}
    container_name: postiz-frontend-prod
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT:-4200}:4200"
    environment:
      <<: *common-variables
      SERVICE_NAME: frontend
    depends_on:
      - backend
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4200/api/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s
    logging: *default-logging
    labels:
      - "service=frontend"
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`${DOMAIN:-localhost}`)"
      - "traefik.http.services.frontend.loadbalancer.server.port=4200"
    networks:
      - postiz-prod
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"

  # ============================================================================
  # Backend Service (NestJS API)
  # ============================================================================
  backend:
    build:
      context: .
      dockerfile: Dockerfile
      target: backend
    image: postiz/backend:${VERSION:-latest}
    container_name: postiz-backend-prod
    restart: unless-stopped
    ports:
      - "${BACKEND_PORT:-3000}:3000"
    environment:
      <<: *common-variables
      SERVICE_NAME: backend
    depends_on:
      - db
      - redis
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 60s
    logging: *default-logging
    labels:
      - "service=backend"
      - "traefik.enable=true"
      - "traefik.http.routers.backend.rule=Host(`api.${DOMAIN:-localhost}`)"
      - "traefik.http.services.backend.loadbalancer.server.port=3000"
    networks:
      - postiz-prod
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
        reservations:
          memory: 512M
          cpus: "0.5"

  # ============================================================================
  # Workers Service (Background Tasks)
  # ============================================================================
  workers:
    build:
      context: .
      dockerfile: Dockerfile
      target: workers
    image: postiz/workers:${VERSION:-latest}
    container_name: postiz-workers-prod
    restart: unless-stopped
    environment:
      <<: *common-variables
      SERVICE_NAME: workers
    depends_on:
      - db
      - redis
    healthcheck:
      test: ["CMD", "pgrep", "-f", "workers"]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 60s
    logging: *default-logging
    labels:
      - "service=workers"
    networks:
      - postiz-prod
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
        reservations:
          memory: 512M
          cpus: "0.5"
      replicas: 2

  # ============================================================================
  # Cron Service (Scheduled Tasks)  
  # ============================================================================
  cron:
    build:
      context: .
      dockerfile: Dockerfile
      target: cron
    image: postiz/cron:${VERSION:-latest}
    container_name: postiz-cron-prod
    restart: unless-stopped
    environment:
      <<: *common-variables
      SERVICE_NAME: cron
    depends_on:
      - db
      - redis
    healthcheck:
      test: ["CMD", "pgrep", "-f", "cron"]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 60s
    logging: *default-logging
    labels:
      - "service=cron"
    networks:
      - postiz-prod
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"

  # ============================================================================
  # Database (PostgreSQL) - Use AWS RDS in production
  # ============================================================================
  db:
    image: postgres:17-alpine
    container_name: postiz-db-prod
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_NAME:-postiz}
      POSTGRES_USER: ${DB_USER:-postiz}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/db-backup.sh:/docker-entrypoint-initdb.d/backup.sh:ro
    ports:
      - "${DB_PORT:-5432}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-postiz} -d ${DB_NAME:-postiz}"]
      interval: 30s
      timeout: 5s
      retries: 5
    logging: *default-logging
    networks:
      - postiz-prod
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"
        reservations:
          memory: 512M
          cpus: "0.5"

  # ============================================================================
  # Redis Cache - Use AWS ElastiCache in production
  # ============================================================================
  redis:
    image: redis:7-alpine
    container_name: postiz-redis-prod
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 256mb --maxmemory-policy allkeys-lru
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
      - ./scripts/redis.conf:/etc/redis/redis.conf:ro
    ports:
      - "${REDIS_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 3s
      retries: 3
    logging: *default-logging
    networks:
      - postiz-prod
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
        reservations:
          memory: 256M
          cpus: "0.25"

  # ============================================================================
  # Reverse Proxy (Traefik) - Use AWS ALB in production
  # ============================================================================
  traefik:
    image: traefik:v3.0
    container_name: postiz-traefik-prod
    restart: unless-stopped
    command:
      - --api.dashboard=true
      - --api.insecure=true
      - --providers.docker=true
      - --providers.docker.exposedbydefault=false
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --certificatesresolvers.letsencrypt.acme.httpchallenge=true
      - --certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web
      - --certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL}
      - --certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json
      - --log.level=INFO
      - --accesslog=true
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik_letsencrypt:/letsencrypt
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.traefik.rule=Host(`traefik.${DOMAIN:-localhost}`)"
    networks:
      - postiz-prod
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.25"

# ============================================================================
# Volumes
# ============================================================================
volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_PATH:-./data}/postgres
  redis_data:
    driver: local
    driver_opts:
      type: none  
      o: bind
      device: ${DATA_PATH:-./data}/redis
  traefik_letsencrypt:
    driver: local

# ============================================================================
# Networks
# ============================================================================
networks:
  postiz-prod:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16